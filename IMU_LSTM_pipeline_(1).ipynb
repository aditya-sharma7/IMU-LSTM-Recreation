{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnoushkaKareCode111/AnoushkaKareCode111/blob/main/IMU_LSTM_pipeline_zenodo_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83fc70a2",
      "metadata": {
        "id": "83fc70a2"
      },
      "source": [
        "# IMU-based HAR & Payload Estimation\n",
        "This notebook reproduces the experiments from the paper.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "02fbdf29",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "02fbdf29",
        "outputId": "51598462-710e-4aea-e911-297d9531b874"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.19.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -q scikit-learn scipy nbformat\n",
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "\n",
        "\n",
        "import os, glob, re, math, random, json, time\n",
        "import numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score, accuracy_score\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks\n",
        "from scipy.signal import butter, filtfilt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "seed = 1234\n",
        "np.random.seed(seed); random.seed(seed); tf.random.set_seed(seed)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Reproducibility seeds ====\n",
        "import os, random, numpy as np, tensorflow as tf\n",
        "\n",
        "SEED = 42\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "print(\"Random seed fixed to\", SEED)\n",
        "# ===============================\n"
      ],
      "metadata": {
        "id": "q3Z8znUSk7oV",
        "outputId": "09c1c55c-c72b-4ee4-e6b8-958e161b5814",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "id": "q3Z8znUSk7oV",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seed fixed to 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "91ced8b9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "91ced8b9",
        "outputId": "119e4275-14f9-4b6d-b4b4-bc868c6e6bf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Detected subjects (files present): ['U001', 'U002', 'U003', 'U004', 'U005', 'U006', 'U007', 'U008', 'U009', 'U010', 'U011', 'U012']\n",
            "Expected subjects: ['U001', 'U002', 'U003', 'U004', 'U005', 'U006', 'U007', 'U008', 'U009', 'U010', 'U011', 'U012']\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# EDIT: set this to the folder where you put the Zenodo CSV files\n",
        "BASE_PATH = \"/content/drive/MyDrive/imu_project/\"  # <<-- change if needed\n",
        "\n",
        "files = os.listdir(BASE_PATH)\n",
        "subjects = sorted({ fname.split('_')[0] for fname in files if fname.startswith('U') })\n",
        "print('Detected subjects (files present):', subjects)\n",
        "expected = [f\"U{str(i).zfill(3)}\" for i in range(1,13)]\n",
        "print('Expected subjects:', expected)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "6b961d36",
      "metadata": {
        "id": "6b961d36"
      },
      "outputs": [],
      "source": [
        "def detect_label_columns(df):\n",
        "    cols = df.columns.str.lower()\n",
        "    label_candidates = [c for c in df.columns if re.search(r'(label|action|intent|intention|class)', c, re.I)]\n",
        "    payload_candidates = [c for c in df.columns if re.search(r'(payload|weight|mass)', c, re.I)]\n",
        "    timestamp_candidates = [c for c in df.columns if re.search(r'(time|timestamp|ts)', c, re.I)]\n",
        "    return {\n",
        "        'label_col': label_candidates[0] if label_candidates else None,\n",
        "        'payload_col': payload_candidates[0] if payload_candidates else None,\n",
        "        'timestamp_col': timestamp_candidates[0] if timestamp_candidates else None\n",
        "    }\n",
        "\n",
        "def detect_sensor_columns(df, exclude_cols):\n",
        "    sensor_cols = [c for c in df.select_dtypes(include=[np.number]).columns if c not in exclude_cols]\n",
        "    return sensor_cols\n",
        "\n",
        "from scipy.signal import butter, filtfilt\n",
        "\n",
        "def lowpass_filtfilt(df, cols, fs=100, cutoff=5.0, order=4):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    out = df.copy()\n",
        "    for c in cols:\n",
        "        try:\n",
        "            out[c] = filtfilt(b, a, df[c].astype(float).to_numpy(), padlen=3*(max(len(a),len(b))-1))\n",
        "        except Exception:\n",
        "            out[c] = df[c].astype(float).to_numpy()\n",
        "    return out\n",
        "\n",
        "\n",
        "def sliding_windows(X, y, window_size, step):\n",
        "    Xs, ys = [], []\n",
        "    T = X.shape[0]\n",
        "    for start in range(0, T - window_size + 1, step):\n",
        "        end = start + window_size\n",
        "        Xw = X[start:end, :]\n",
        "        yw = y[start:end]\n",
        "        vals, counts = np.unique(yw, return_counts=True)\n",
        "        label = vals[np.argmax(counts)]\n",
        "        Xs.append(Xw)\n",
        "        ys.append(label)\n",
        "    return np.array(Xs), np.array(ys)\n",
        "\n",
        "\n",
        "def derive_action_and_interaction(labels):\n",
        "    actions = []\n",
        "    inters  = []\n",
        "    for v in labels:\n",
        "        s = str(v).lower()\n",
        "        if 'walk' in s:\n",
        "            actions.append('walk'); inters.append('none')\n",
        "        elif 'stand' in s or 'idle' in s:\n",
        "            actions.append('stand'); inters.append('none')\n",
        "        elif 'lift' in s:\n",
        "            actions.append('interact'); inters.append('lift')\n",
        "        elif 'lower' in s or 'put' in s:\n",
        "            actions.append('interact'); inters.append('lower')\n",
        "        else:\n",
        "            actions.append('stand'); inters.append('none')\n",
        "    return np.array(actions), np.array(inters)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "c4d69204",
      "metadata": {
        "id": "c4d69204"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def build_har_model(input_shape, n_action=3, n_inter=2):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = layers.LSTM(100, return_sequences=True)(inputs)\n",
        "    x = layers.LSTM(50)(x)\n",
        "    x = layers.Dense(20, activation='relu')(x)\n",
        "    out_action = layers.Dense(n_action, activation='softmax', name='action')(x)\n",
        "    out_inter  = layers.Dense(n_inter, activation='softmax', name='interaction')(x)\n",
        "    model = models.Model(inputs, [out_action, out_inter])\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss={'action':'categorical_crossentropy', 'interaction':'categorical_crossentropy'},\n",
        "                  metrics={'action':'accuracy','interaction':'accuracy'})\n",
        "    return model\n",
        "\n",
        "def build_payload_model(input_shape, n_classes=3):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = layers.LSTM(100, return_sequences=True)(inputs)\n",
        "    x = layers.LSTM(50)(x)\n",
        "    x = layers.Dense(20, activation='relu')(x)\n",
        "    out_payload = layers.Dense(n_classes, activation='softmax', name='payload')(x)\n",
        "    model = models.Model(inputs, out_payload)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "6a99c1c7",
      "metadata": {
        "id": "6a99c1c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "38aeb081-0f80-4be9-8c3b-2b01a82f6925"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== SUBJECT U001 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/ops/nn.py:944: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/losses/losses.py:33: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/ops/nn.py:944: UserWarning: You are using a softmax over axis -1 of a tensor of shape (32, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HAR action F1: 1.0 interaction F1: 1.0\n",
            "Payload F1: 0.895 Acc: 0.892\n",
            "\n",
            "Saved results to /content/drive/MyDrive/imu_project/all_subjects_results.csv\n",
            "Median HAR action F1: 1.0\n",
            "Median HAR interaction F1: 1.0\n",
            "Median Payload F1: 0.8950520903492653\n"
          ]
        }
      ],
      "source": [
        "FS = 100\n",
        "CUTOFF = 5.0\n",
        "WIN_SEC = 1.0\n",
        "WIN = int(WIN_SEC * FS)\n",
        "STEP = WIN // 2\n",
        "\n",
        "all_results = []\n",
        "\n",
        "FAST_MODE = True   # change to False to run ALL 12 subjects\n",
        "\n",
        "if FAST_MODE:\n",
        "    subj_list = [\"U001\"]   # runs quickly\n",
        "else:\n",
        "    subj_list = [f\"U{str(i).zfill(3)}\" for i in range(1,13)]  # full experiment\n",
        "\n",
        "\n",
        "for SUBJ in subj_list:\n",
        "    print('\\n===== SUBJECT', SUBJ, '=====')\n",
        "    patt = os.path.join(BASE_PATH, f\"{SUBJ}_*.csv\")\n",
        "    files = sorted(glob.glob(patt))\n",
        "    if not files:\n",
        "        print('No files for', SUBJ, '- skipping')\n",
        "        continue\n",
        "    data = { os.path.basename(f): pd.read_csv(f, low_memory=False) for f in files }\n",
        "    train_int = data.get(f\"{SUBJ}_train_intention.csv\")\n",
        "    val_int   = data.get(f\"{SUBJ}_val_intention.csv\")\n",
        "    test_int  = data.get(f\"{SUBJ}_test_intention.csv\")\n",
        "    if train_int is None or test_int is None:\n",
        "        print('Missing intention files for', SUBJ); continue\n",
        "    train_int_full = pd.concat([train_int, val_int], ignore_index=True) if val_int is not None else train_int\n",
        "    det = detect_label_columns(train_int_full)\n",
        "    LABEL_COL_INTENTION = det['label_col'] or det['payload_col'] or train_int_full.columns[-1]\n",
        "    TIMESTAMP_COL = det['timestamp_col']\n",
        "    exclude = [LABEL_COL_INTENTION] + ([TIMESTAMP_COL] if TIMESTAMP_COL else [])\n",
        "    sensor_cols = detect_sensor_columns(train_int_full, exclude)\n",
        "    train_int_filt = lowpass_filtfilt(train_int_full, sensor_cols, fs=FS, cutoff=CUTOFF, order=4)\n",
        "    test_int_filt  = lowpass_filtfilt(test_int, sensor_cols, fs=FS, cutoff=CUTOFF, order=4)\n",
        "    scaler = MinMaxScaler(feature_range=(-1,1))\n",
        "    scaler.fit(train_int_filt[sensor_cols])\n",
        "    Xtr = scaler.transform(train_int_filt[sensor_cols])\n",
        "    Xte = scaler.transform(test_int_filt[sensor_cols])\n",
        "    ytr_raw = train_int_filt[LABEL_COL_INTENTION].values\n",
        "    yte_raw = test_int_filt[LABEL_COL_INTENTION].values\n",
        "    Xtr_seq, ytr_win = sliding_windows(Xtr, ytr_raw, WIN, STEP)\n",
        "    Xte_seq, yte_win = sliding_windows(Xte, yte_raw, WIN, STEP)\n",
        "    if len(Xtr_seq)==0 or len(Xte_seq)==0:\n",
        "        print('Not enough windows for', SUBJ); continue\n",
        "    action_tr, inter_tr = derive_action_and_interaction(ytr_win)\n",
        "    action_te, inter_te = derive_action_and_interaction(yte_win)\n",
        "    le_act = LabelEncoder(); le_act.fit(np.concatenate([action_tr, action_te]))\n",
        "    le_int = LabelEncoder(); le_int.fit(np.concatenate([inter_tr, inter_te]))\n",
        "    Yact_tr = to_categorical(le_act.transform(action_tr))\n",
        "    Yact_te = to_categorical(le_act.transform(action_te))\n",
        "    Yint_tr = to_categorical(le_int.transform(inter_tr))\n",
        "    Yint_te = to_categorical(le_int.transform(inter_te))\n",
        "    input_shape = Xtr_seq.shape[1:]\n",
        "    har_model = build_har_model(input_shape, n_action=Yact_tr.shape[1], n_inter=Yint_tr.shape[1])\n",
        "    es = callbacks.EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
        "    history = har_model.fit(Xtr_seq, {'action':Yact_tr, 'interaction':Yint_tr},\n",
        "                            validation_data=(Xte_seq, {'action':Yact_te, 'interaction':Yint_te}),\n",
        "                            epochs=60, batch_size=64, callbacks=[es], verbose=0)\n",
        "    pred_act, pred_int = har_model.predict(Xte_seq, verbose=0)\n",
        "    yhat_act = le_act.inverse_transform(np.argmax(pred_act, axis=1))\n",
        "    yhat_int = le_int.inverse_transform(np.argmax(pred_int, axis=1))\n",
        "    f1_act = f1_score(action_te, yhat_act, average='weighted')\n",
        "    f1_int = f1_score(inter_te, yhat_int, average='weighted')\n",
        "    acc_act = accuracy_score(action_te, yhat_act)\n",
        "    acc_int = accuracy_score(inter_te, yhat_int)\n",
        "    print('HAR action F1:', round(f1_act,3), 'interaction F1:', round(f1_int,3))\n",
        "    train_pay = data.get(f\"{SUBJ}_train_payload.csv\")\n",
        "    val_pay   = data.get(f\"{SUBJ}_val_payload.csv\")\n",
        "    test_pay  = data.get(f\"{SUBJ}_test_payload.csv\")\n",
        "    if train_pay is None or test_pay is None:\n",
        "        print('Missing payload files for', SUBJ); continue\n",
        "    train_pay_full = pd.concat([train_pay, val_pay], ignore_index=True) if val_pay is not None else train_pay\n",
        "    detp = detect_label_columns(train_pay_full)\n",
        "    PAY_COL = detp['payload_col'] or train_pay_full.columns[-1]\n",
        "    sensor_cols_pay = detect_sensor_columns(train_pay_full, [PAY_COL])\n",
        "    train_pay_filt = lowpass_filtfilt(train_pay_full, sensor_cols_pay, fs=FS, cutoff=CUTOFF, order=4)\n",
        "    test_pay_filt  = lowpass_filtfilt(test_pay, sensor_cols_pay, fs=FS, cutoff=CUTOFF, order=4)\n",
        "    scaler_pay = MinMaxScaler(feature_range=(-1,1))\n",
        "    scaler_pay.fit(train_pay_filt[sensor_cols_pay])\n",
        "    Xtr_pay = scaler_pay.transform(train_pay_filt[sensor_cols_pay])\n",
        "    Xte_pay = scaler_pay.transform(test_pay_filt[sensor_cols_pay])\n",
        "    ytr_pay_raw = train_pay_filt[PAY_COL].values\n",
        "    yte_pay_raw = test_pay_filt[PAY_COL].values\n",
        "    Xtr_pay_seq, ytr_pay_win = sliding_windows(Xtr_pay, ytr_pay_raw, WIN, STEP)\n",
        "    Xte_pay_seq, yte_pay_win = sliding_windows(Xte_pay, yte_pay_raw, WIN, STEP)\n",
        "    if len(Xtr_pay_seq)==0 or len(Xte_pay_seq)==0:\n",
        "        print('Not enough payload windows for', SUBJ); continue\n",
        "    le_pay = LabelEncoder(); le_pay.fit(np.concatenate([ytr_pay_win, yte_pay_win]))\n",
        "    Ytr_pay = to_categorical(le_pay.transform(ytr_pay_win))\n",
        "    Yte_pay = to_categorical(le_pay.transform(yte_pay_win))\n",
        "    payload_model = build_payload_model(Xtr_pay_seq.shape[1:], n_classes=Ytr_pay.shape[1])\n",
        "    es2 = callbacks.EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
        "    payload_model.fit(Xtr_pay_seq, Ytr_pay, validation_data=(Xte_pay_seq, Yte_pay), epochs=60, batch_size=64, callbacks=[es2], verbose=0)\n",
        "    pred_pay = payload_model.predict(Xte_pay_seq, verbose=0)\n",
        "    yhat_pay = le_pay.inverse_transform(np.argmax(pred_pay, axis=1))\n",
        "    f1_pay = f1_score(yte_pay_win, yhat_pay, average='weighted')\n",
        "    acc_pay = accuracy_score(yte_pay_win, yhat_pay)\n",
        "    print('Payload F1:', round(f1_pay,3), 'Acc:', round(acc_pay,3))\n",
        "    all_results.append({'subject':SUBJ,\n",
        "                        'har_action_f1':float(f1_act),'har_inter_f1':float(f1_int),'har_action_acc':float(acc_act),'har_inter_acc':float(acc_int),\n",
        "                        'payload_f1':float(f1_pay),'payload_acc':float(acc_pay)})\n",
        "    tf.keras.backend.clear_session()\n",
        "    time.sleep(1)\n",
        "\n",
        "# Save CSV of results and compute medians\n",
        "import pandas as pd\n",
        "if len(all_results)>0:\n",
        "    df_res = pd.DataFrame(all_results)\n",
        "    out_csv = os.path.join(BASE_PATH, 'all_subjects_results.csv')\n",
        "    df_res.to_csv(out_csv, index=False)\n",
        "    print('\\nSaved results to', out_csv)\n",
        "    print('Median HAR action F1:', df_res['har_action_f1'].median())\n",
        "    print('Median HAR interaction F1:', df_res['har_inter_f1'].median())\n",
        "    print('Median Payload F1:', df_res['payload_f1'].median())\n",
        "else:\n",
        "    print('No results to save.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "c3ebd41d",
      "metadata": {
        "id": "c3ebd41d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "88dbc131-b11d-453f-dd9e-5c24f8923b69"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  subject  har_action_f1  har_inter_f1  har_action_acc  har_inter_acc  \\\n",
              "0    U001            1.0           1.0             1.0            1.0   \n",
              "\n",
              "   payload_f1  payload_acc  \n",
              "0    0.895052     0.891832  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-22ae0c4a-c243-46ed-a154-609fb9edd3ea\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subject</th>\n",
              "      <th>har_action_f1</th>\n",
              "      <th>har_inter_f1</th>\n",
              "      <th>har_action_acc</th>\n",
              "      <th>har_inter_acc</th>\n",
              "      <th>payload_f1</th>\n",
              "      <th>payload_acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>U001</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.895052</td>\n",
              "      <td>0.891832</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22ae0c4a-c243-46ed-a154-609fb9edd3ea')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-22ae0c4a-c243-46ed-a154-609fb9edd3ea button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-22ae0c4a-c243-46ed-a154-609fb9edd3ea');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_fc50a1c8-a09a-4cb5-9074-ac93d5dd5f0f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_res')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_fc50a1c8-a09a-4cb5-9074-ac93d5dd5f0f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_res');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_res",
              "summary": "{\n  \"name\": \"df_res\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"subject\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"U001\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"har_action_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"har_inter_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"har_action_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"har_inter_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"payload_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.8950520903492653,\n        \"max\": 0.8950520903492653,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8950520903492653\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"payload_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.891832229580574,\n        \"max\": 0.891832229580574,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.891832229580574\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Medians:\n",
            "HAR action F1 median: 1.0\n",
            "HAR interaction F1 median: 1.0\n",
            "Payload F1 median: 0.8950520903492653\n"
          ]
        }
      ],
      "source": [
        "res_path = os.path.join(BASE_PATH, 'all_subjects_results.csv')\n",
        "if os.path.exists(res_path):\n",
        "    df_res = pd.read_csv(res_path)\n",
        "    display(df_res)\n",
        "    print('Medians:')\n",
        "    print('HAR action F1 median:', df_res['har_action_f1'].median())\n",
        "    print('HAR interaction F1 median:', df_res['har_inter_f1'].median())\n",
        "    print('Payload F1 median:', df_res['payload_f1'].median())\n",
        "else:\n",
        "    print('Results file not found. Run previous cell first.')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}